# -*- coding: utf-8 -*-
"""Insurance data Analytics

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1p19Kv1X0WX8iDG55hsiFMpB9nUV1MDTF
"""

# Import laibreries

import pandas as pd
import numpy as np

# Load Data

claims_df=pd.read_csv("/content/Insurance data/claims_data.csv")
policyholders_df=pd.read_csv("/content/Insurance data/policyholders_data.csv")

# Clean Data claims

claims_df=claims_df.drop_duplicates()
claims_df=claims_df.dropna()
claims_df['claim_amount']=pd.to_numeric(claims_df['claim_amount'], errors='coerce')
claims_df['claim_date']=pd.to_datetime(claims_df['claim_date'])

# Clean Data Policyhoders

policyholders_df=policyholders_df.drop_duplicates()
policyholders_df=policyholders_df.dropna()
policyholders_df['age']=pd.to_numeric(policyholders_df['age'], errors='coerce')
policyholders_df['premium_amount']=pd.to_numeric(policyholders_df['premium_amount'], errors='coerce')

# merge teo data sets

merged_df=pd.merge(claims_df, policyholders_df, on='policyholder_id', how= 'left')

# Add calculated columns

merged_df['claims_to_premium_ratio']=merged_df['claim_amount']/merged_df['premium_amount']
merged_df['fraud_risk_score']=np.where(merged_df['fraud_suspect'] == 'yes', 0.8, 0.2)

merged_df.to_csv('merged_df.csv', index=False)

#print(merged_df)